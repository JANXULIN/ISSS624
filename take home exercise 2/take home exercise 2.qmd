---
title: "take home exercise 2 Singapore public bus commuter flows"
author: "Xu Lin"
---

# overview 

We currently have data on people's movement patterns as well as information on schools, businesses, and retail activities in different areas. The goal of this task is to identify common Saturday activities among the population. Through our analysis, we aim to provide recommendations to the government, suggesting potential enhancements to existing facilities or proposing the development of new amenities that align with people's preferences. The objective is to make these facilities more appealing and strategically located for the community's convenience.

# Objective 

Our goal is to pinpoint popular weekend destinations, analyze the main facilities in those areas, and provide recommendations accordingly.

# Data Geospatial data: 

Passenger Volume by Origin Destination Bus Stops, Bus Stop Location, Train Station and Train Station Exit Point, Master Plan 2019 Subzone Boundary, HDB Property Information, Business, Entertn, F&B, FinServ, Leisure&Recreation and Retails. Aspatial data: HDB Property Information. This data is for us to use.

# Mmethodology ：

1，Prepare hexagonal data.
2，Draw the flow data map for Saturday morning.
3，Prepare the destination data for customer activities on Saturday.
4，Data integration.
5，Model.
6，Visualization.
7, Limitation

# 1，Prepare hexagonal data.

```{r}
pacman::p_load(tmap, sf, DT, stplanr, sp, dplyr,
               performance, reshape2, units, 
               ggpubr, tidyverse, mapview, httr, sfheaders, knitr, kableExtra)
```

## Importing the OD data

```{r}
odbus <- read_csv("data/aspatial/origin_destination_bus_202310.csv")
```

```{r}
odbus$ORIGIN_PT_CODE <- as.factor(odbus$ORIGIN_PT_CODE)
odbus$DESTINATION_PT_CODE <- as.factor(odbus$DESTINATION_PT_CODE) 
```

```{r}
glimpse(odbus)
```

```{r}
weekendmorning11_14 <- odbus %>%
  filter(DAY_TYPE == "WEEKENDS/HOLIDAY") %>%
  filter(TIME_PER_HOUR >= 11 & TIME_PER_HOUR <= 14) %>%
  group_by(ORIGIN_PT_CODE, DESTINATION_PT_CODE) %>%
  summarise(TRIPS = sum(TOTAL_TRIPS), .groups = 'keep')
```

```{r}
datatable(weekendmorning11_14)
```

```{r}
write_rds(weekendmorning11_14, "data/rds/weekendmorning11_14.rds")
```

```{r}
weekendmorning11_14 <- read_rds("data/rds/weekendmorning11_14.rds")
```

## busstop points

```{r}
busstop <- st_read(dsn = "data/geospatial", layer = "BusStop") %>%
  st_transform(crs = 3414)
```

```{r}
glimpse(busstop)
```

```{r}
busstop_points = busstop %>%
  st_as_sf(coords = c("geometry"), crs = 3414, remove = FALSE)
```

```{r}
mapview_busstop_points = mapview(busstop_points, cex = 0.5, alpha = .5, popup = NULL)
mapview_busstop_points
```

```{r}
area_honeycomb_grid = st_make_grid(busstop_points, c(750, 750), what = "polygons", square = FALSE)
honeycomb_grid_sf = st_sf(area_honeycomb_grid) %>%
  mutate(grid_id = 1:length(lengths(area_honeycomb_grid)))
honeycomb_grid_sf$n_colli = lengths(st_intersects(honeycomb_grid_sf, busstop_points))
honeycomb_count = filter(honeycomb_grid_sf, n_colli > 0)
```

```{r}
write_rds(honeycomb_count, "data/rds/honeycomb_count.rds")
```

```{r}
map_honeycomb = tm_shape(honeycomb_count) +
  tm_fill(
    col = "n_colli",
    palette = "Reds",
    style = "cont",
    title = "Number of collisions",
    id = "grid_id",
    showNA = FALSE,
    alpha = 0.6,
    popup.vars = c(
      "Number of collisions: " = "n_colli"
    ),
    popup.format = list(
      n_colli = list(format = "f", digits = 0)
    )
  ) +
  tm_borders(col = "grey40", lwd = 0.7)
map_honeycomb
```

```{r}
busstop_honeycomb_count <- st_intersection(busstop, honeycomb_count) %>%
  select(BUS_STOP_N, grid_id) %>%
  st_drop_geometry()
```

```{r}
glimpse(busstop_honeycomb_count)
```

```{r}
write_rds(busstop_honeycomb_count, "data/rds/busstop_honeycomb_count.rds")  
```

# 2,Draw the flow data map for Saturday morning.

```{r}
weekendmorning11_14 <- left_join(weekendmorning11_14 , busstop_honeycomb_count,
            by = c("ORIGIN_PT_CODE" = "BUS_STOP_N")) %>%
  rename(ORIGIN_BS = ORIGIN_PT_CODE,
         ORIGIN_SZ = grid_id,
         DESTIN_BS = DESTINATION_PT_CODE)
```

```{r}
duplicate <- weekendmorning11_14 %>%
  group_by_all() %>%
  filter(n()>1) %>%
  ungroup()
```

```{r}
weekendmorning11_14 <- unique(weekendmorning11_14)
```

```{r}
weekendmorning11_14 <- left_join(weekendmorning11_14 , busstop_honeycomb_count,
            by = c("DESTIN_BS" = "BUS_STOP_N")) 
```

```{r}
duplicate <- weekendmorning11_14 %>%
  group_by_all() %>%
  filter(n()>1) %>%
  ungroup()
```

```{r}
weekendmorning11_14 <- unique(weekendmorning11_14)
```

```{r}
weekendmorning11_14 <- weekendmorning11_14 %>%
  rename(DESTIN_SZ = grid_id) %>%
  drop_na() %>%
  group_by(ORIGIN_SZ, DESTIN_SZ) %>%
  summarise(WEEKENDDAYMORNING_PEAK = sum(TRIPS))
```

```{r}
write_rds(weekendmorning11_14, "data/rds/weekendmorning11_14.rds")
```

```{r}
weekendmorning11_14 <- read_rds("data/rds/weekendmorning11_14.rds")
```

```{r}
weekendmorning11_14_1 <- weekendmorning11_14[weekendmorning11_14$ORIGIN_SZ!=weekendmorning11_14$DESTIN_SZ,]
```

```{r}
flowLine <- od2line(flow = weekendmorning11_14_1, 
                    zones = honeycomb_count,
                    zone_code = "grid_id")
```

```{r}
tm_shape(honeycomb_count) +
  tm_polygons() +
flowLine %>%  
tm_shape() +
  tm_lines(lwd = "WEEKENDDAYMORNING_PEAK",
           style = "quantile",
           scale = c(0.1, 1, 3, 5, 7, 10),
           n = 6,
           alpha = 0.3)
```

```{r}
tm_shape(honeycomb_count) +
  tm_polygons() +
flowLine %>%  
  filter(WEEKENDDAYMORNING_PEAK >= 2000) %>%
tm_shape() +
  tm_lines(lwd = "WEEKENDDAYMORNING_PEAK",
           style = "quantile",
           scale = c(0.1, 1, 3, 5, 7, 10),
           n = 6,
           alpha = 0.3)
```

## Caculate the distance

```{r}
honeycomb_count <- read_rds("data/rds/honeycomb_count.rds")
honeycomb_count
```

```{r}
honeycomb_count_sp <- as(honeycomb_count, "Spatial")
honeycomb_count_sp
```

```{r}
dist <- spDists(honeycomb_count_sp, 
                longlat = FALSE)
head(dist, n=c(10, 10))
```

```{r}
sz_names <- honeycomb_count$grid_id
```

```{r}
colnames(dist) <- paste0(sz_names)
rownames(dist) <- paste0(sz_names)
```

```{r}
distPair <- melt(dist) %>%
  rename(dist = value)
head(distPair, 10)
```

```{r}
distPair %>%
  filter(dist > 0) %>%
  summary()
```

```{r}
distPair$dist <- ifelse(distPair$dist == 0,
                        50, distPair$dist)
```

```{r}
distPair %>%
  summary()
```

```{r}
distPair <- distPair %>%
  rename(orig = Var1,
         dest = Var2)
```

```{r}
write_rds(distPair, "data/rds/distPair.rds") 
```

```{r}
weekendmorning11_14 <- read_rds("data/rds/weekendmorning11_14.rds")
```

```{r}
flow_data <- weekendmorning11_14 %>%
  group_by(ORIGIN_SZ, DESTIN_SZ) %>% 
  summarize(TRIPS = sum(WEEKENDDAYMORNING_PEAK)) 
```

```{r}
head(flow_data)
```

```{r}
flow_data$FlowNoIntra <- ifelse(
  flow_data$ORIGIN_SZ == flow_data$DESTIN_SZ, 
  0, flow_data$TRIPS)
flow_data$offset <- ifelse(
  flow_data$ORIGIN_SZ == flow_data$DESTIN_SZ, 
  0.000001, 1)
```

```{r}
flow_data$ORIGIN_SZ <- as.integer(flow_data$ORIGIN_SZ)
flow_data$DESTIN_SZ <- as.integer(flow_data$DESTIN_SZ)
distPair$orig <- as.integer(distPair$orig)
distPair$dest <- as.integer(distPair$dest)
distPair$dist <- as.integer(distPair$dist)
```

```{r}
flow_data1 <- flow_data %>%
  left_join (distPair,
             by = c("ORIGIN_SZ" = "orig",
                    "DESTIN_SZ" = "dest"))
```

```{r}
glimpse(flow_data1)
```

```{r}
flow_data1 <- flow_data1 %>%
  left_join(honeycomb_count,
            by = c("DESTIN_SZ" = "grid_id")) %>%
  rename(DIST = dist)
```

```{r}
summary(flow_data1)
```

```{r}
write_rds(flow_data1,
          "data/rds/flow_data1.rds")
```

#3，Prepare the destination data for customer activities on Saturday.

## Schools

```{r}
url<-"https://www.onemap.gov.sg/api/common/elastic/search"

csv<-read_csv("data/aspatial/Generalinformationofschools.csv")
postcodes<-csv$`postal_code`

found<-data.frame()
not_found<-data.frame()

for(postcode in postcodes){
  query<-list('searchVal'=postcode,'returnGeom'='Y','getAddrDetails'='Y','pageNum'='1')
  res<- GET(url,query=query)
  
  if((content(res)$found)!=0){
    found<-rbind(found,data.frame(content(res))[4:13])
  } else{
    not_found = data.frame(postcode)
  }
}
```

```{r}
merged = merge(csv, found, by.x = 'postal_code', by.y = 'results.POSTAL', all = TRUE)
write.csv(merged, file = "data/aspatial/schools.csv")
write.csv(not_found, file = "data/aspatial/not_found.csv")
```

```{r}
schools <- read_csv("data/aspatial/schools.csv") %>%
  rename(latitude = "results.LATITUDE",
         longitude = "results.LONGITUDE")%>%
  select(postal_code, school_name, latitude, longitude)
```

```{r}
schools <- schools[complete.cases(schools$longitude, schools$latitude), ]
schools_sf <- st_as_sf(schools, 
                       coords = c("longitude", "latitude"),
                       crs=4326) %>%
  st_transform(crs = 3414)
```

```{r}
tmap_options(check.and.fix = TRUE)
tm_shape(honeycomb_count) +
  tm_polygons() +
tm_shape(schools_sf) +
  tm_dots()
tmap_mode("plot")
```

```{r}
honeycomb_count$`SCHOOL_COUNT`<- lengths(
  st_intersects(
   honeycomb_count, schools_sf))
```

```{r}
summary(honeycomb_count$SCHOOL_COUNT)
```

## RapidTransitSystemStation

```{r}
RTSS_sf <- st_read(dsn = "data/geospatial/",
                layer = "RapidTransitSystemStation")%>%
  st_transform(crs = 3414)
```

```{r}
RTSS_sf_polygons <- RTSS_sf[st_is_valid(RTSS_sf), ]
RTSS_sf_points <- st_centroid(RTSS_sf_polygons)
```

```{r}
tmap_options(check.and.fix = TRUE)
tm_shape(honeycomb_count) +
  tm_polygons() +
tm_shape(RTSS_sf_points) +
  tm_dots()
tmap_mode("plot")
```

```{r}
honeycomb_count$`RTSS_COUNT`<- lengths(
  st_intersects(
    honeycomb_count, RTSS_sf_points))
```

```{r}
summary(honeycomb_count$`RTSS_COUNT`)
```

## Entertn

```{r}
entertn_sf <- st_read(dsn = "data/geospatial/",
                layer = "entertn")%>%
  st_transform(crs = 3414)
```

```{r}
tmap_options(check.and.fix = TRUE)
tm_shape(honeycomb_count) +
  tm_polygons() +
tm_shape(entertn_sf) +
  tm_dots()
tmap_mode("plot")
```

```{r}
honeycomb_count$`ENTERTN_COUNT`<- lengths(
  st_intersects(
    honeycomb_count, entertn_sf))
```

```{r}
summary(honeycomb_count$ENTERTN_COUNT)
```

## Liesure&Recreation

```{r}
lr_sf <- st_read(dsn = "data/geospatial/",
                                    layer = "Liesure&Recreation") %>%
  st_transform(crs = 3414)
```

```{r}
tmap_options(check.and.fix = TRUE)
tm_shape(honeycomb_count) +
  tm_polygons() +
tm_shape(lr_sf) +
  tm_dots()
tmap_mode("plot")
```

```{r}
honeycomb_count$`LR_COUNT`<- lengths(
  st_intersects(
    honeycomb_count, lr_sf))
```

```{r}
summary(honeycomb_count$LR_COUNT)
```

## Retails

```{r}
retails_sf <- st_read(dsn = "data/geospatial/",
                layer = "Retails")%>%
  st_transform(crs = 3414)
```

```{r}
tmap_options(check.and.fix = TRUE)
tm_shape(honeycomb_count) +
  tm_polygons() +
tm_shape(retails_sf) +
  tm_dots()
tmap_mode("plot")
```

```{r}
honeycomb_count$`RETAILS_COUNT`<- lengths(
  st_intersects(
    honeycomb_count, retails_sf))
```

```{r}
glimpse(honeycomb_count$RETAILS_COUNT)
```

# 4,Data integration.

```{r}
honeycomb_count_tidy <- honeycomb_count %>%
  st_drop_geometry() %>%
  select(grid_id, SCHOOL_COUNT, RTSS_COUNT, ENTERTN_COUNT, LR_COUNT, RETAILS_COUNT)
```

```{r}
flow_data2 <- flow_data1 %>%
  left_join(honeycomb_count_tidy,
            by = c("DESTIN_SZ" = "grid_id")) 
```

```{r}
glimpse(flow_data2)
```

```{r}
flow_data2$SCHOOL_COUNT <- ifelse(
  flow_data2$SCHOOL_COUNT == 0,
  0.99, flow_data2$SCHOOL_COUNT)
flow_data2$RTSS_COUNT <- ifelse(
  flow_data2$RTSS_COUNT == 0,
  0.99, flow_data2$RTSS_COUNT)
flow_data2$ENTERTN_COUNT <- ifelse(
  flow_data2$ENTERTN_COUNT == 0,
  0.99, flow_data2$ENTERTN_COUNT)
flow_data2$LR_COUNT <- ifelse(
  flow_data2$LR_COUNT == 0,
  0.99, flow_data2$LR_COUNT)
flow_data2$RETAILS_COUNT <- ifelse(
  flow_data2$RETAILS_COUNT == 0,
  0.99, flow_data2$RETAILS_COUNT)
```

```{r}
summary(flow_data2)
```

```{r}
write_rds(flow_data2,
          "data/rds/flow_data_tidy.rds")
```

```{r}
flow_data3 <- read_rds("data/rds/flow_data_tidy.rds")
```

```{r}
flow_data3 <- flow_data2 %>%
  mutate(ORIGIN_SZ = as.character(ORIGIN_SZ), DESTIN_SZ = as.character(DESTIN_SZ))
```

```{r}
glimpse(flow_data3)
```

```{r}
kable(head(flow_data3[, 1:5], n = 5))
```

```{r}
flow_data3$FlowNoIntra <- ifelse(
  flow_data3$ORIGIN_SZ == flow_data3$DESTIN_SZ, 
  0, flow_data3$TRIPS)
flow_data3$offset <- ifelse(
  flow_data3$ORIGIN_SZ == flow_data3$DESTIN_SZ, 
  0.000001, 1)
```

```{r}
inter_zonal_flow <- flow_data3 %>%
  filter(FlowNoIntra > 0)
```

```{r}
glimpse(inter_zonal_flow)
```

# 5,Model

## Origin_Constrained model

```{r}
orcSIM_Poisson <- glm(formula = TRIPS ~ 
                ORIGIN_SZ +
                log(SCHOOL_COUNT) +  
                log(ENTERTN_COUNT) +
                log(RTSS_COUNT) + 
                log(LR_COUNT) +
                log(RETAILS_COUNT) +
                log(DIST) - 1,
              family = poisson(link = "log"),
              data = inter_zonal_flow,
              na.action = na.exclude)
summary(orcSIM_Poisson)
```

```{r}
CalcRSquared <- function(observed, estimated){
  r <- cor(observed, estimated)
  R2 <- r^2
  R2
}
```

```{r}
CalcRSquared(orcSIM_Poisson$data$TRIPS, orcSIM_Poisson$fitted.values)
```

### Conclusion of Origin_Constrained model

Currently, the OM model yields an R-squared value of 44%, indicating that the model explains approximately 44% of the variance in the response variable TRIPS. The significant p-values suggest that the model is effective, as these values indicate statistically significant impacts of the explanatory variables on the response variable. However, given that the fit is only 44%, it is necessary to explore comparisons with different models. This suggests that there might be unexplained variability, possibly due to important variables not included in the model or complex nonlinear relationships not captured by the current model. Therefore, further analysis is required to enhance the explanatory power of the model.

## Doubly_Constrained model

```{r}
dbcSIM_Poisson <- glm(formula = TRIPS ~ 
                ORIGIN_SZ + 
                DESTIN_SZ +
                log(DIST),
              family = poisson(link = "log"),
              data = inter_zonal_flow,
              na.action = na.exclude)
summary(dbcSIM_Poisson)
```

```{r}
CalcRSquared(dbcSIM_Poisson$data$TRIPS,
             dbcSIM_Poisson$fitted.values)
```

### Conclusion of Doubly_Constrained model

Doubly_Constrained model demonstrates significant statistical strength, with all P-values being less than the 0.05 threshold, indicating a significant positive effect of the variables in the model on the predicted outcomes. The R-squared value of the model is 66.8%, suggesting that it accounts for a substantial portion of the variability in the response variable, indicating a good fit. Additionally, the model required 10 iterations of Fisher Scoring to converge, showing that the model underwent a reasonable number of iterations before reaching the optimal solution. Overall, the performance of this doubly constrained model is quite satisfactory. It effectively captures key features of the data, providing reliable predictions of the response variable. However, given that there is still room for improvement in the residual deviance, further exploration of additional explanatory variables or model adjustments might be needed to optimize performance and enhance explanatory power.

```{r}
model_list <- list(
  Origin_Constrained = orcSIM_Poisson,
  Doubly_Constrained = dbcSIM_Poisson)
```

```{r}
compare_performance(model_list,
                    metrics = "RMSE")
```
### Modle Camparation Conclusion 

The smaller the RMSE value, the smaller the error of the model. From the results, it can be seen that the Doubly Constrained Model (glm) has a smaller error compared to the Origin Constrained Model (glm). Consequently, in terms of performance, the Doubly Constrained Model (glm) is superior to the Origin Constrained Model (glm).

# 6,Visualization.

```{r}
df <- as.data.frame(orcSIM_Poisson$fitted.values) %>%
  round(digits = 0)
```

```{r}
inter_zonal_flow <- inter_zonal_flow %>%
  cbind(df) %>%
  rename(orcTRIPS = "orcSIM_Poisson$fitted.values")
```

```{r}
df <- as.data.frame(dbcSIM_Poisson$fitted.values) %>%
  round(digits = 0)
```

```{r}
inter_zonal_flow <- inter_zonal_flow %>%
  cbind(df) %>%
  rename(dbcTRIPS1 = "dbcSIM_Poisson$fitted.values")
```

```{r}
orc_p <- ggplot(data = inter_zonal_flow,
                aes(x = orcTRIPS,
                    y = TRIPS)) +
  geom_point() +
  geom_smooth(method = lm) +
  coord_cartesian(xlim=c(0,150000),
                  ylim=c(0,150000))

dbc_p <- ggplot(data = inter_zonal_flow,
                aes(x = dbcTRIPS1,
                    y = TRIPS)) +
  geom_point() +
  geom_smooth(method = lm) +
  coord_cartesian(xlim=c(0,150000),
                  ylim=c(0,150000))
```

```{r}
ggarrange(orc_p, dbc_p,
          ncol = 2,
          nrow = 1)
```

## Conclusion of Visualization

The chart indicates that the Doubly_Constrained Model has a better fit than the Origin_Constrained Model, as evidenced by the smaller dispersion of points around the trend line, which suggests a lower error in the Doubly_Constrained Model compared to the Origin_Constrained Model.

# 7,Limitations

Limitations: 
1，We have only compared two models; ideally, we could compare a wider range of models to select the most optimal one.
2，The data used were selectively chosen, which introduces the possibility of subjective bias in the dataset.
3，The model could benefit from a stepwise evaluation to determine if reducing the number of variables might increase the fit.
4，Due to memory limitations, 'mapview' cannot be used and the image lacks boundaries.









